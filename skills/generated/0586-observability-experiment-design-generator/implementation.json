{
  "version": 1,
  "sourceFile": "SKILL_UPDATES_1000.md",
  "skillId": 586,
  "skillName": "u0586-observability-experiment-design-generator",
  "title": "Observability Experiment Design Generator",
  "domain": "Data Quality and Observability",
  "domainSlug": "data-quality-and-observability",
  "reason": "We need this skill because decisions are only as good as the quality and visibility of data. This specific skill converts unknowns into testable learning loops.",
  "implementationGuide": [
    "Define the scope and success metrics for `Observability Experiment Design Generator`, including at least three measurable KPIs tied to data drift and blind spots.",
    "Design and version the input/output contract for freshness, drift, schema health, and telemetry coverage, then add schema validation and failure-mode handling.",
    "Implement the core capability using hypothesis-driven design, and produce experiment plans with deterministic scoring.",
    "Integrate the skill into swarm orchestration: task routing, approval gates, retry strategy, and rollback controls.",
    "Add unit, integration, and simulation tests that explicitly cover data drift and blind spots, then run regression baselines.",
    "Deploy behind a feature flag, monitor telemetry/alerts for two release cycles, and iterate thresholds based on observed outcomes."
  ],
  "runtimeProfile": {
    "archetype": "general-capability",
    "coreMethod": "hypothesis-driven design",
    "primaryArtifact": "experiment plans",
    "requiredSignals": [
      "freshness",
      "drift",
      "schema health",
      "telemetry coverage",
      "claims",
      "evidence",
      "confidence traces"
    ],
    "kpiFocus": [
      "data drift",
      "blind spots",
      "decision drift"
    ],
    "scoringWeights": {
      "truth": 0.2523,
      "execution": 0.1572,
      "safety": 0.3258,
      "impact": 0.2647
    },
    "postureThresholds": {
      "readyMin": 71,
      "reviewMin": 51,
      "reviewRisk": 46,
      "criticalRisk": 70
    },
    "orchestration": {
      "routingTag": "data-quality-and-observability:general-capability",
      "approvalGates": [
        "policy-constraint-check",
        "human-approval-router"
      ],
      "retryPolicy": {
        "maxAttempts": 3,
        "baseDelayMs": 750,
        "backoff": "exponential"
      },
      "rollbackStrategy": "rollback-to-last-stable-baseline",
      "components": [
        "task routing",
        "approval gates",
        "retry strategy",
        "rollback controls"
      ]
    },
    "validation": {
      "suites": [
        "unit",
        "integration",
        "simulation",
        "regression-baseline"
      ],
      "baselineRequired": true
    },
    "rollout": {
      "featureFlag": "skill_0586_observability-experiment-design-",
      "releaseCycles": 2,
      "telemetryAlerts": true
    },
    "scoringSeed": "u0586-observability-experiment-design-generator:586:general-capability",
    "ioContract": {
      "inputs": [
        {
          "name": "freshness",
          "type": "signal",
          "required": true,
          "source": "upstream"
        },
        {
          "name": "drift",
          "type": "signal",
          "required": true,
          "source": "upstream"
        },
        {
          "name": "schema health",
          "type": "signal",
          "required": true,
          "source": "upstream"
        },
        {
          "name": "telemetry coverage",
          "type": "signal",
          "required": true,
          "source": "upstream"
        },
        {
          "name": "claims",
          "type": "signal",
          "required": true,
          "source": "upstream"
        },
        {
          "name": "evidence",
          "type": "signal",
          "required": true,
          "source": "upstream"
        },
        {
          "name": "confidence traces",
          "type": "signal",
          "required": true,
          "source": "upstream"
        }
      ],
      "outputs": [
        {
          "name": "experiment_plans_report",
          "type": "structured-report",
          "guaranteed": true,
          "consumer": "orchestrator"
        },
        {
          "name": "experiment_plans_scorecard",
          "type": "scorecard",
          "guaranteed": true,
          "consumer": "operator"
        }
      ]
    },
    "validationGates": [
      {
        "gate": "schema-contract-check",
        "check": "All required input signals present and schema-valid",
        "onFail": "quarantine"
      },
      {
        "gate": "determinism-check",
        "check": "Repeated run on same inputs yields stable scoring and artifacts",
        "onFail": "escalate"
      },
      {
        "gate": "policy-approval-check",
        "check": "Approval gates satisfied before publish-level outputs",
        "onFail": "retry"
      }
    ],
    "failureHandling": {
      "knownFailures": [
        {
          "code": "E_INPUT_SCHEMA",
          "trigger": "Missing or malformed required signals",
          "action": "Reject payload, emit validation error, request corrected payload"
        },
        {
          "code": "E_NON_DETERMINISM",
          "trigger": "Determinism delta exceeds allowed threshold",
          "action": "Freeze output, escalate to human approval router"
        },
        {
          "code": "E_DEPENDENCY_TIMEOUT",
          "trigger": "Downstream or external dependency timeout",
          "action": "Apply retry policy then rollback to last stable baseline"
        }
      ],
      "rollbackStrategy": "rollback-to-last-stable-baseline"
    },
    "handoffContract": {
      "produces": [
        "Observability Experiment Design Generator normalized artifacts",
        "execution scorecard",
        "risk posture"
      ],
      "consumes": [
        "freshness",
        "drift",
        "schema health",
        "telemetry coverage",
        "claims",
        "evidence",
        "confidence traces"
      ],
      "downstreamHint": "Route next to data-quality-and-observability:general-capability consumers with approval-gate context"
    }
  },
  "traceability": {
    "scopeStep": "Define the scope and success metrics for `Observability Experiment Design Generator`, including at least three measurable KPIs tied to data drift and blind spots.",
    "contractStep": "Design and version the input/output contract for freshness, drift, schema health, and telemetry coverage, then add schema validation and failure-mode handling.",
    "coreStep": "Implement the core capability using hypothesis-driven design, and produce experiment plans with deterministic scoring.",
    "orchestrationStep": "Integrate the skill into swarm orchestration: task routing, approval gates, retry strategy, and rollback controls.",
    "validationStep": "Add unit, integration, and simulation tests that explicitly cover data drift and blind spots, then run regression baselines.",
    "rolloutStep": "Deploy behind a feature flag, monitor telemetry/alerts for two release cycles, and iterate thresholds based on observed outcomes."
  }
}
