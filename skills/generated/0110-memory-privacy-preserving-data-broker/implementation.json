{
  "version": 1,
  "sourceFile": "SKILL_UPDATES_1000.md",
  "skillId": 110,
  "skillName": "u0110-memory-privacy-preserving-data-broker",
  "title": "Memory Privacy Preserving Data Broker",
  "domain": "Memory and Knowledge Operations",
  "domainSlug": "memory-and-knowledge-operations",
  "reason": "We need this skill because agents lose performance when lessons are not retained and reused. This specific skill enables collaboration while minimizing raw data exposure.",
  "implementationGuide": [
    "Define the scope and success metrics for `Memory Privacy Preserving Data Broker`, including at least three measurable KPIs tied to repeated mistakes and context loss.",
    "Design and version the input/output contract for episodic logs, knowledge nodes, and retrieval metadata, then add schema validation and failure-mode handling.",
    "Implement the core capability using policy-scoped data mediation, and produce privacy-scoped exchanges with deterministic scoring.",
    "Integrate the skill into swarm orchestration: task routing, approval gates, retry strategy, and rollback controls.",
    "Add unit, integration, and simulation tests that explicitly cover repeated mistakes and context loss, then run regression baselines.",
    "Deploy behind a feature flag, monitor telemetry/alerts for two release cycles, and iterate thresholds based on observed outcomes."
  ],
  "runtimeProfile": {
    "archetype": "collaboration-mediator",
    "coreMethod": "policy-scoped data mediation",
    "primaryArtifact": "privacy-scoped exchanges",
    "requiredSignals": [
      "episodic logs",
      "knowledge nodes",
      "retrieval metadata",
      "claims",
      "evidence",
      "confidence traces"
    ],
    "kpiFocus": [
      "repeated mistakes",
      "context loss",
      "decision drift"
    ],
    "scoringWeights": {
      "truth": 0.3108,
      "execution": 0.2219,
      "safety": 0.1324,
      "impact": 0.3349
    },
    "postureThresholds": {
      "readyMin": 75,
      "reviewMin": 49,
      "reviewRisk": 31,
      "criticalRisk": 68
    },
    "orchestration": {
      "routingTag": "memory-and-knowledge-operations:collaboration-mediator",
      "approvalGates": [
        "policy-constraint-check",
        "human-approval-router"
      ],
      "retryPolicy": {
        "maxAttempts": 3,
        "baseDelayMs": 600,
        "backoff": "exponential"
      },
      "rollbackStrategy": "rollback-to-last-stable-baseline",
      "components": [
        "task routing",
        "approval gates",
        "retry strategy",
        "rollback controls"
      ]
    },
    "validation": {
      "suites": [
        "unit",
        "integration",
        "simulation",
        "regression-baseline"
      ],
      "baselineRequired": true
    },
    "rollout": {
      "featureFlag": "skill_0110_memory-privacy-preserving-data-b",
      "releaseCycles": 2,
      "telemetryAlerts": true
    },
    "scoringSeed": "u0110-memory-privacy-preserving-data-broker:110:collaboration-mediator"
  },
  "traceability": {
    "scopeStep": "Define the scope and success metrics for `Memory Privacy Preserving Data Broker`, including at least three measurable KPIs tied to repeated mistakes and context loss.",
    "contractStep": "Design and version the input/output contract for episodic logs, knowledge nodes, and retrieval metadata, then add schema validation and failure-mode handling.",
    "coreStep": "Implement the core capability using policy-scoped data mediation, and produce privacy-scoped exchanges with deterministic scoring.",
    "orchestrationStep": "Integrate the skill into swarm orchestration: task routing, approval gates, retry strategy, and rollback controls.",
    "validationStep": "Add unit, integration, and simulation tests that explicitly cover repeated mistakes and context loss, then run regression baselines.",
    "rolloutStep": "Deploy behind a feature flag, monitor telemetry/alerts for two release cycles, and iterate thresholds based on observed outcomes."
  }
}
